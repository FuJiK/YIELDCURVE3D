{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import requests\n",
    "import xml.etree.ElementTree as et\n",
    "from xml.parsers.expat import ExpatError\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import urllib.request as urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled file: /Users/fujiokaken/Docs/Github/yieldcurvedata/data/xml/2023.xml\n"
     ]
    }
   ],
   "source": [
    "#---- Scrape XML From Treasury Website ----#\n",
    "year  = 2023\n",
    "curpath = os.path.dirname(os.path.realpath(\"./yield\"))\n",
    "data_dir = data_dir = curpath + '/data/xml'\n",
    "while (year <=2023):\n",
    "    filename = os.path.join(data_dir, '%s.xml' %year )\n",
    "    resp = urllib2.urlopen('http://data.treasury.gov/feed.svc/DailyTreasuryYieldCurveRateData?$filter=year(NEW_DATE)%20eq%20'+ str(year))\n",
    "    xml = resp.read()\n",
    "    with open(filename, \"wb\") as file:\n",
    "        file.write(xml)\n",
    "        print(\"Pulled file: %s\" % filename)    \n",
    "    year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Retrieve XML Files --------#\n",
    "# Current  directory:\n",
    "curpath = os.path.dirname( os.path.abspath(\"./yield/\"))\n",
    "\n",
    "# Traverse a directory\n",
    "data_dir = curpath + '/data/'\n",
    "def traverse_directory(directory):\n",
    "    files = [directory+f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Prepend Namespaces for Retrieval ----#\n",
    "def prepend_atom(s):\n",
    "    return '{http://www.w3.org/2005/Atom}' + s\n",
    "\n",
    "def prepend_schema(s):\n",
    "    return '{http://schemas.microsoft.com/ado/2007/08/dataservices/metadata}%s' % s\n",
    "\n",
    "def prepend_ds(s):\n",
    "    return '{http://schemas.microsoft.com/ado/2007/08/dataservices}%s' % s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Build a Dictionary of All Entries from 1990 to Present  ----#\n",
    "def build_entries_dict(count, dentries, root):\n",
    "    for elem in root.findall(prepend_atom('entry')):\n",
    "        count +=1\n",
    "        dentry = {}\n",
    "        properties = elem.find(prepend_atom('content')).find(prepend_schema('properties'))\n",
    "        iid = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('Id')).text\n",
    "        date = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('NEW_DATE')).text\n",
    "        bc_1month = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_1MONTH')).text\n",
    "        bc_3month = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_3MONTH')).text\n",
    "        bc_6month = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_6MONTH')).text\n",
    "        bc_1yr = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_1YEAR')).text\n",
    "        bc_2yr = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_2YEAR')).text\n",
    "        bc_3yr = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_3YEAR')).text\n",
    "        bc_5yr = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_5YEAR')).text\n",
    "        bc_7yr = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_7YEAR')).text\n",
    "        bc_10yr = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_10YEAR')).text\n",
    "        bc_30yr = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_30YEAR')).text\n",
    "        bc_30yr_display = elem.find(prepend_atom('content')).find(prepend_schema('properties')).find(prepend_ds('BC_30YEARDISPLAY')).text\n",
    "        dentry['date'] = date\n",
    "        dentry['1m'] = bc_1month\n",
    "        dentry['3m'] = bc_3month\n",
    "        dentry['6m'] = bc_6month\n",
    "        dentry['1y'] = bc_1yr\n",
    "        dentry['2y'] = bc_2yr\n",
    "        dentry['3y'] = bc_3yr\n",
    "        dentry['5y'] = bc_5yr\n",
    "        dentry['7y'] = bc_7yr\n",
    "        dentry['10y'] = bc_10yr\n",
    "        dentry['30y'] = bc_30yr\n",
    "        dentries[iid] = dentry\n",
    "    return dentries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Parse the XML to create a Dict of All Data ---#\n",
    "def parse_xml(filename, count, dentries):\n",
    "    try:\n",
    "        #Parse the given XML file:\n",
    "        tree = et.parse(filename)\n",
    "    except ExpatError as e:\n",
    "        print (\"[XML] Error (line %d): %d\" % (e.lineno, e.code))\n",
    "        print (\"[XML] Offset: %d\" % (e.offset))\n",
    "        raise e\n",
    "    except IOError as e:\n",
    "        print (\"[XML] I/O Error %d: %s\" % (e.errno, e.strerror))\n",
    "        raise e\n",
    "    else:\n",
    "        root = tree.getroot()\n",
    "        dentries = build_entries_dict(count, dentries, root)\n",
    "    return dentries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Main --------#\n",
    "count = 0\n",
    "dentries = {}\n",
    "curpath = os.path.dirname( os.path.abspath(\"./yield\"))\n",
    "data_dir = curpath + '/data/xml/'\n",
    "xml_files = traverse_directory(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 6, column 45 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.anyenv/envs/pyenv/versions/3.9.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3442\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[78], line 2\u001b[0m\n    dentries = parse_xml(f, count, dentries)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[76], line 5\u001b[0m in \u001b[1;35mparse_xml\u001b[0m\n    tree = et.parse(filename)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.anyenv/envs/pyenv/versions/3.9.9/lib/python3.9/xml/etree/ElementTree.py:1229\u001b[0m in \u001b[1;35mparse\u001b[0m\n    tree.parse(source, parser)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/.anyenv/envs/pyenv/versions/3.9.9/lib/python3.9/xml/etree/ElementTree.py:580\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    self._root = parser._parse_whole(source)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m not well-formed (invalid token): line 6, column 45\n"
     ]
    }
   ],
   "source": [
    "for f in xml_files:\n",
    "    dentries = parse_xml(f, count, dentries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load JSON Into Pandas DataFrame ----#\n",
    "# Convert dict to JSON\n",
    "json_entries = json.dumps(dentries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Panda Dataframe\n",
    "df = pd.read_json(json_entries, convert_dates=True, convert_axes=True, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['date', '1m', '3m', '6m', '1y', '2y', '3y', '5y', '7y', '10y', '30y'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m6m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m5y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m7y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m30y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.anyenv/envs/pyenv/versions/3.9.9/lib/python3.9/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.anyenv/envs/pyenv/versions/3.9.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.anyenv/envs/pyenv/versions/3.9.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['date', '1m', '3m', '6m', '1y', '2y', '3y', '5y', '7y', '10y', '30y'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df = df[['date','1m', '3m', '6m', '1y', '2y', '3y', '5y', '7y', '10y', '30y']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['10y/6m'] = df['10y']/df['6m']\n",
    "df['10y/1y'] = df['10y']/df['1y']\n",
    "df['10y/2y'] = df['10y']/df['2y']\n",
    "df['10y/3y'] = df['10y']/df['3y']\n",
    "df['10y/5y'] = df['10y']/df['5y']\n",
    "df['10y/7y'] = df['10y']/df['7y']\n",
    "df['30y/10y'] = df['30y']/df['10y']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('3.9.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c95522b8610f0d060f1fbdf33cabdb485b8ccc74d5b9792def75a3c555f9532"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
